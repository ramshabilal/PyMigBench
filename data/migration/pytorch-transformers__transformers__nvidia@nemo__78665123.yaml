repo: nvidia/nemo
commit: 786651234cc92e1bb1d14e44aa5e207867f85596
source: pytorch-transformers
target: transformers
commit_url: https://github.com/nvidia/nemo/commit/78665123
domain: Deep Learning
files:
- path: "collections/nemo_nlp/nemo_nlp/data/tokenizers/bert_tokenizer.py"
  code_changes:
  - line: "2:2"
    cardinality: not applicable
    source_program_elements: [import]
    target_program_elements: [import]
    properties: []
    source_apis: [pytorch_transformers.BertTokenizer]
    target_apis: [transformers.BertTokenizer]
- path: "collections/nemo_nlp/nemo_nlp/data/tokenizers/gpt2_tokenizer.py"
  code_changes:
  - line: "2:2"
    cardinality: not applicable
    source_program_elements: [import]
    target_program_elements: [import]
    properties: []
    source_apis: [pytorch_transformers.GPT2Tokenizer]
    target_apis: [transformers.GPT2Tokenizer]
- path: "collections/nemo_nlp/nemo_nlp/huggingface/bert.py"
  code_changes:
  - line: "7-10:4-7"
    cardinality: not applicable
    source_program_elements: [import]
    target_program_elements: [import]
    properties: []
    source_apis: [pytorch_transformers.BERT_PRETRAINED_CONFIG_ARCHIVE_MAP, pytorch_transformers.BERT_PRETRAINED_MODEL_ARCHIVE_MAP, pytorch_transformers.BertConfig, pytorch_transformers.BertModel]
    target_apis: [transformers.BERT_PRETRAINED_CONFIG_ARCHIVE_MAP, transformers.BERT_PRETRAINED_MODEL_ARCHIVE_MAP, transformers.BertConfig, transformers.BertModel]
- path: "examples/nlp/joint_intent_slot_infer.py"
  code_changes:
  - line: "5:5"
    cardinality: not applicable
    source_program_elements: [import]
    target_program_elements: [import]
    properties: []
    source_apis: [pytorch_transformers.BertTokenizer]
    target_apis: [transformers.BertTokenizer]
- path: "examples/nlp/joint_intent_slot_infer_b1.py"
  code_changes:
  - line: "4:4"
    cardinality: not applicable
    source_program_elements: [import]
    target_program_elements: [import]
    properties: []
    source_apis: [pytorch_transformers.BertTokenizer]
    target_apis: [transformers.BertTokenizer]
- path: "examples/nlp/joint_intent_slot_with_bert.py"
  code_changes:
  - line: "6:6"
    cardinality: not applicable
    source_program_elements: [import]
    target_program_elements: [import]
    properties: []
    source_apis: [pytorch_transformers.BertTokenizer]
    target_apis: [transformers.BertTokenizer]
- path: "examples/nlp/sentence_classification_with_bert.py"
  code_changes:
  - line: "5:5"
    cardinality: not applicable
    source_program_elements: [import]
    target_program_elements: [import]
    properties: []
    source_apis: [pytorch_transformers.BertTokenizer]
    target_apis: [transformers.BertTokenizer]
- path: "scripts/get_decoder_params_from_bert.py"
  code_changes:
  - line: "2-3:2-3"
    cardinality: not applicable
    source_program_elements: [import]
    target_program_elements: [import]
    properties: []
    source_apis: [pytorch_transformers.BERT_PRETRAINED_MODEL_ARCHIVE_MAP, pytorch_transformers.file_utils.cached_path]
    target_apis: [transformers.BERT_PRETRAINED_MODEL_ARCHIVE_MAP, transformers.file_utils.cached_path]
